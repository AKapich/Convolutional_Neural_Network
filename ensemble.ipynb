{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('drive/MyDrive')\n",
        "os.listdir('src')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmh-7-_XLZT2",
        "outputId": "25e01be3-423d-4cf7-c1c0-917ae379fec1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['models', '__pycache__', 'model_trainer.py', 'transformations.py', 'utils.py']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeP2uoE6LVP1",
        "outputId": "a03fb427-a444-46c5-fb30-64c033c44952"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "from src.models.our_model import OurModel\n",
        "from src.models.pretrained_models import VGG16Pretrained, ResNetPretrained\n",
        "import torch\n",
        "from src.models.ensemble import HardVotingEnsemble, SoftVotingEnsemble\n",
        "from src.utils import load_data, evaluate_model\n",
        "from src.model_trainer import ModelTrainer\n",
        "from src.transformations import normalized_simple_transform\n",
        "device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device = torch.device(device_str)\n",
        "torch.manual_seed(123)\n",
        "print(device)\n",
        "torch.set_num_threads(2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cell for donwloading data\n",
        "\n",
        "import os\n",
        "import tarfile\n",
        "import urllib.request\n",
        "import shutil\n",
        "\n",
        "download_dir = \"/data\"\n",
        "\n",
        "if not os.path.exists(download_dir):\n",
        "    os.makedirs(download_dir)\n",
        "\n",
        "tar_path = os.path.join(download_dir, \"CINIC-10.tar.gz\")\n",
        "cinic10_url = \"https://datashare.is.ed.ac.uk/bitstream/handle/10283/3192/CINIC-10.tar.gz\"\n",
        "urllib.request.urlretrieve(cinic10_url, tar_path)\n",
        "print(\"Finished downloading\")\n",
        "\n",
        "with tarfile.open(tar_path, \"r:gz\") as tar:\n",
        "    tar.extractall(path=download_dir)\n",
        "\n",
        "extracted_dir = os.path.join(download_dir, \"CINIC-10\")\n",
        "\n",
        "if os.path.exists(extracted_dir) and os.path.isdir(extracted_dir):\n",
        "    for item in os.listdir(extracted_dir):\n",
        "        src_path = os.path.join(extracted_dir, item)\n",
        "        dst_path = os.path.join(download_dir, item)\n",
        "        shutil.move(src_path, dst_path)\n",
        "\n",
        "print(download_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2r_rxgHmLh1h",
        "outputId": "af7d24fe-4d2c-47ec-a25e-1c9ed35f511e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished downloading\n",
            "/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8K6Iek_PLVP6"
      },
      "outputs": [],
      "source": [
        "test_loader = load_data('/data/test', batch_size=256, shuffle=True, transform=normalized_simple_transform(), num_workers=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## all models ensemble"
      ],
      "metadata": {
        "id": "Kn_7nI_8OIS8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIbATryMLVP7",
        "outputId": "db4bdead-ca19-4099-ef8a-ea2612e39177"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 165MB/s]\n"
          ]
        }
      ],
      "source": [
        "vgg16 = VGG16Pretrained(device=\"cpu\")\n",
        "vgg16.load_state_dict(torch.load(\"./saved_models/vgg_pretrained/horizontal_flip_20/VGG16Pretrained_20.pth\", map_location=device))\n",
        "vgg16.to(device)\n",
        "ourmodel = OurModel(aux_enabled=False, se_squeeze=8)\n",
        "ourmodel.load_state_dict(torch.load(\"./saved_models/ourmodel/combined_20/OurModel_16.pth\", map_location=device))\n",
        "ourmodel.to(device)\n",
        "resnet = ResNetPretrained()\n",
        "resnet.load_state_dict(torch.load(\"./saved_models/resnet/final/ResNetPretrained_20.pth\", map_location=device))\n",
        "resnet.to(device)\n",
        "base_models = [ourmodel, vgg16, resnet]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4djhdWoiLVP8",
        "outputId": "e687f8e6-cd6b-4c5d-e7a0-60e8ef5c54f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HardVotingEnsemble()"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "hard_vot_ensemble = HardVotingEnsemble(base_models)\n",
        "hard_vot_ensemble.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtKwYNknLVP9",
        "outputId": "f5e6c2d9-d478-476f-81ff-7c62bcf6fe61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 \n",
            " {'accuracy': 0.8021777777777778, 'f1_score': 0.8009975569622965, 'roc_auc': None}\n"
          ]
        }
      ],
      "source": [
        "metrics_hard = evaluate_model(hard_vot_ensemble, test_loader, device)\n",
        "print(f\"\\n {metrics_hard}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylhkr4FeLVP9",
        "outputId": "04877190-ddce-4141-f9f5-9e23140212f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SoftVotingEnsemble()"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "soft_vot_ensemble = SoftVotingEnsemble(base_models)\n",
        "soft_vot_ensemble.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f3y0d8BLVP-",
        "outputId": "30adaab5-d2e3-4f9c-e5b2-66ee69a2f689"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 \n",
            " {'accuracy': 0.8170777777777778, 'f1_score': 0.8157499424139534, 'roc_auc': None}\n"
          ]
        }
      ],
      "source": [
        "metrics_soft = evaluate_model(soft_vot_ensemble, test_loader, device)\n",
        "print(f\"\\n {metrics_soft}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}