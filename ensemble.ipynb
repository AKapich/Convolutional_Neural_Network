{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from src.models.our_model import OurModel\n",
    "from src.models.pretrained_models import VGG16Pretrained, ResNetPretrained\n",
    "import torch\n",
    "from src.models.ensemble import HardVotingEnsemble, SoftVotingEnsemble\n",
    "from src.utils import load_data, evaluate_model\n",
    "from src.model_trainer import ModelTrainer\n",
    "from src.transformations import normalized_simple_transform\n",
    "device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device_str)\n",
    "torch.manual_seed(123)\n",
    "print(device)\n",
    "torch.set_num_threads(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = load_data('./data/test', batch_size=512, shuffle=True, transform=normalized_simple_transform(), num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karim\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\karim\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "vgg16 = VGG16Pretrained(device=\"cpu\")  \n",
    "vgg16.load_state_dict(torch.load(\"./saved_models/vgg_pretrained/regularization_params_001_2/VGG16Pretrained_10.pth\", map_location=device))\n",
    "vgg16.to(device)\n",
    "ourmodel = OurModel(aux_enabled=False, se_squeeze=8)  \n",
    "ourmodel.load_state_dict(torch.load(\"./saved_models/ourmodel/combined_20/OurModel_16.pth\", map_location=device))\n",
    "ourmodel.to(device)\n",
    "base_models = [ourmodel, vgg16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HardVotingEnsemble()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_vot_ensemble = HardVotingEnsemble(base_models)\n",
    "hard_vot_ensemble.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 470 480 490 500 510 520 530 540 550 560 570 580 590 600 610 620 630 640 650 660 670 680 690 700 {'accuracy': 0.7492888888888889, 'f1_score': 0.7495402521392662, 'roc_auc': None}\n"
     ]
    }
   ],
   "source": [
    "metrics_hard = evaluate_model(hard_vot_ensemble, test_loader, device)\n",
    "print(f\"\\n {metrics_hard}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SoftVotingEnsemble()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_vot_ensemble = SoftVotingEnsemble(base_models)\n",
    "soft_vot_ensemble.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 470 480 490 500 510 520 530 540 550 560 570 580 590 600 610 620 630 640 650 660 670 680 690 700 {'accuracy': 0.7959333333333334, 'f1_score': 0.7961234438510887, 'roc_auc': None}\n"
     ]
    }
   ],
   "source": [
    "metrics_soft = evaluate_model(soft_vot_ensemble, test_loader, device)\n",
    "print(f\"\\n {metrics_soft}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 "
     ]
    }
   ],
   "source": [
    "metrics_soft = evaluate_model(soft_vot_ensemble, test_loader, device)\n",
    "print(f\"\\n {metrics_soft}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
