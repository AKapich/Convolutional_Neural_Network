{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.our_model import OurModel\n",
    "from src.models.pretrained_models import VGG16Pretrained, ResNetPretrained\n",
    "import torch\n",
    "from src.models.ensemble import HardVotingEnsemble, SoftVotingEnsemble, MetaClassifier, StackingEnsemble\n",
    "from src.utils import load_data, evaluate_model\n",
    "from src.model_trainer import ModelTrainer\n",
    "from src.transformations import normalized_simple_transform\n",
    "device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device_str)\n",
    "torch.manual_seed(123)\n",
    "print(device)\n",
    "torch.set_num_threads(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "model1 = OurModel()  \n",
    "model1.load_state_dict(torch.load(\".\\saved_models\\ourmodel\\combined_20\\OurModel_16.pth\", map_location=device))\n",
    "model1.to(device)\n",
    "\n",
    "model2 = OurModel()  \n",
    "model2.load_state_dict(torch.load(\".\\saved_models\\ourmodel\\combined_20\\OurModel_16.pth\", map_location=device))\n",
    "model2.to(device)\n",
    "\n",
    "model3 = OurModel()  \n",
    "model3.load_state_dict(torch.load(\".\\saved_models\\ourmodel\\combined_20\\OurModel_20.pth\", map_location=device))\n",
    "model3.to(device)\n",
    "\n",
    "# model2 = VGG16Pretrained()\n",
    "# model2.load_state_dict(torch.load(model2_path, map_location=device))\n",
    "# model2.to(device)\n",
    "\n",
    "# model3 = ResNetPretrained()\n",
    "# model3.load_state_dict(torch.load(model3_path, map_location=device))\n",
    "# model3.to(device)\n",
    "\n",
    "base_models = [model1, model2, model3]\n",
    "    \n",
    "meta_input_dim = len(base_models) * 10 \n",
    "meta_model = MetaClassifier(meta_input_dim, 10)\n",
    "meta_model.to(device)\n",
    "\n",
    "stacking_ensemble = StackingEnsemble(base_models, meta_model, use_probs=True)\n",
    "stacking_ensemble.to(device)\n",
    "\n",
    "test_loader = load_data('./data/test', batch_size=128, shuffle=True, transform=normalized_simple_transform(), num_workers=1)\n",
    "train_loader = load_data('./data/train', batch_size=128, shuffle=True, transform=normalized_simple_transform(), num_workers=1)\n",
    "valid_loader = load_data('./data/valid', batch_size=512, shuffle=True, transform=normalized_simple_transform(), num_workers=1)\n",
    "\n",
    "trainer = ModelTrainer(\n",
    "    model=stacking_ensemble,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    device=device,\n",
    "    optimizer_type=\"adam\",\n",
    "    learning_rate=0.001,\n",
    "    weight_decay=0,\n",
    "    save_dir=\".saved_models/ensemble\",\n",
    "    log_file=\"ensemble.json\"\n",
    ")\n",
    "\n",
    "trainer.train(epochs=10)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
