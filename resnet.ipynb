{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcGM-4q7Ozcv",
        "outputId": "86d413f8-c760-459e-d873-0880f766ca58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "VrKPTybrO2Sv",
        "outputId": "31a141c7-d26d-4e51-e595-073c150c9ecb"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'drive/MyDrive'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e128d7b2b45c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/MyDrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'src'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/MyDrive'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir('drive/MyDrive')\n",
        "os.listdir('src')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uXKynQpDOhq7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchsummary import summary\n",
        "from src.utils import load_data\n",
        "from src.transformations import pretrained_transform\n",
        "from src.models.pretrained_models import ResNetPretrained\n",
        "from src.model_trainer import ModelTrainer\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5td6j10KOvxS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRBd9NQTOhq9",
        "outputId": "eb7a7162-668e-4ddf-a01c-7ae2dab1b47b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7b36ba4597d0>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device = torch.device(device_str)\n",
        "device\n",
        "torch.manual_seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CLFeVt27Ohq-"
      },
      "outputs": [],
      "source": [
        "torch.set_num_threads(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqCJ-azJOhq_",
        "outputId": "f491bd33-60ec-4b0e-f40d-2c54a5fc0557"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished downloading\n",
            "/data\n"
          ]
        }
      ],
      "source": [
        "# cell for donwloading data\n",
        "\n",
        "import os\n",
        "import tarfile\n",
        "import urllib.request\n",
        "import shutil\n",
        "\n",
        "download_dir = \"/data\"\n",
        "\n",
        "if not os.path.exists(download_dir):\n",
        "    os.makedirs(download_dir)\n",
        "\n",
        "tar_path = os.path.join(download_dir, \"CINIC-10.tar.gz\")\n",
        "cinic10_url = \"https://datashare.is.ed.ac.uk/bitstream/handle/10283/3192/CINIC-10.tar.gz\"\n",
        "urllib.request.urlretrieve(cinic10_url, tar_path)\n",
        "print(\"Finished downloading\")\n",
        "\n",
        "with tarfile.open(tar_path, \"r:gz\") as tar:\n",
        "    tar.extractall(path=download_dir)\n",
        "\n",
        "extracted_dir = os.path.join(download_dir, \"CINIC-10\")\n",
        "\n",
        "if os.path.exists(extracted_dir) and os.path.isdir(extracted_dir):\n",
        "    for item in os.listdir(extracted_dir):\n",
        "        src_path = os.path.join(extracted_dir, item)\n",
        "        dst_path = os.path.join(download_dir, item)\n",
        "        shutil.move(src_path, dst_path)\n",
        "\n",
        "print(download_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqTmjMFgOhq_"
      },
      "outputs": [],
      "source": [
        "train_loader = pretrained_transform(\n",
        "    \"/data/train\",\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    transform=pretrained_transform(),\n",
        "    num_workers=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BQbbf7NjOhrA"
      },
      "outputs": [],
      "source": [
        "n_epochs = 10\n",
        "max_batches = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JUN3h4BWOhrB"
      },
      "outputs": [],
      "source": [
        "test_loader = load_data('/data/test', batch_size=128, shuffle=True, transform=pretrained_transform(), num_workers=1)\n",
        "train_loader = load_data('/data/train', batch_size=128, shuffle=True, transform=pretrained_transform(), num_workers=1)\n",
        "valid_loader = load_data('/data/valid', batch_size=128, shuffle=True, transform=pretrained_transform(), num_workers=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEs66FddOhrB"
      },
      "outputs": [],
      "source": [
        "training_process_grid = {\n",
        "    \"optimizer_type\": [\"adam\", \"sgd\"],\n",
        "    \"learning_rate\": [0.01, 0.001, 0.0001],\n",
        "}\n",
        "\n",
        "regularization_grid = {\n",
        "    \"weight_decay\": [0.01, 0.001, 0.0001],\n",
        "    \"dropout\": [0.2, 0.5, 0.7],\n",
        "}\n",
        "\n",
        "# grid search for training parameters with set L1 regularizer = 0 & dropout = 0\n",
        "# grid search for regularization parameters with set optimizer = adam & learning_rate = 0.001\n",
        "\n",
        "training_param_combinations = list(itertools.product(*training_process_grid.values()))\n",
        "regularization_param_combinations = list(\n",
        "    itertools.product(*regularization_grid.values())\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_bz3ibhOhrB",
        "outputId": "ddb9ce64-e7c0-44e3-9c4a-240845c17f77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "is cuda False\n",
            "Batch count 0\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 0.001\n",
        "for optimizer_type in [\"adam\", \"sgd\"]:\n",
        "    resnet = ResNetPretrained()\n",
        "    learning_rate_str = f\"{learning_rate}\".replace(\"0.\", \"\")\n",
        "    trainer = ModelTrainer(\n",
        "        model=resnet,\n",
        "        train_loader=train_loader,\n",
        "        device=device,\n",
        "        weight_decay=0,\n",
        "        optimizer_type=optimizer_type,\n",
        "        learning_rate=learning_rate,\n",
        "        log_file=f\"resnet_{optimizer_type}_{learning_rate}.json\",\n",
        "        save_dir=f\"./saved_models/resnet/training_params_{optimizer_type}_{learning_rate_str}\",\n",
        "        max_batches=max_batches,\n",
        "        valid_loader=valid_loader\n",
        "    )\n",
        "    trainer.train(n_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwcO2gpTOhrC"
      },
      "outputs": [],
      "source": [
        "optimizer_type = \"sgd\"\n",
        "for learning_rate in [0.01, 0.001, 0.0001]:\n",
        "    resnet = ResNetPretrained()\n",
        "    learning_rate_str = f\"{learning_rate}\".replace(\"0.\", \"\")\n",
        "    trainer = ModelTrainer(\n",
        "        model=resnet,\n",
        "        train_loader=train_loader,\n",
        "        device=device,\n",
        "        weight_decay=0,\n",
        "        optimizer_type=optimizer_type,\n",
        "        learning_rate=learning_rate,\n",
        "        log_file=f\"resnet_{optimizer_type}_{learning_rate}.json\",\n",
        "        save_dir=f\"./saved_models/resnet/training_params_{optimizer_type}_{learning_rate_str}\",\n",
        "        max_batches=max_batches,\n",
        "        valid_loader=valid_loader\n",
        "    )\n",
        "    trainer.train(n_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSBwhtn8OhrC",
        "outputId": "e40a62ca-bbe0-44a5-b006-8b5ea934c7e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "is cuda False\n",
            "Batch count 0\n",
            "Epoch 1/1, Loss: 5.0680, Accuracy: 0.3203, F1-score: 0.2255\n",
            "Model saved to ./saved_models/resnet/regularization_params\\ResNetPretrained_1.pth\n",
            "Training log saved to ./saved_models/resnet/regularization_params\\resnet_0.01_0.2.json\n",
            "is cuda False\n",
            "Batch count 0\n",
            "Epoch 1/1, Loss: 3.8199, Accuracy: 0.3398, F1-score: 0.2342\n",
            "Model saved to ./saved_models/resnet/regularization_params\\ResNetPretrained_1.pth\n",
            "Training log saved to ./saved_models/resnet/regularization_params\\resnet_0.01_0.5.json\n",
            "is cuda False\n",
            "Batch count 0\n",
            "Epoch 1/1, Loss: 2.7944, Accuracy: 0.3984, F1-score: 0.2638\n",
            "Model saved to ./saved_models/resnet/regularization_params\\ResNetPretrained_1.pth\n",
            "Training log saved to ./saved_models/resnet/regularization_params\\resnet_0.01_0.7.json\n",
            "is cuda False\n",
            "Batch count 0\n",
            "Epoch 1/1, Loss: 2.2295, Accuracy: 0.4062, F1-score: 0.2750\n",
            "Model saved to ./saved_models/resnet/regularization_params\\ResNetPretrained_1.pth\n",
            "Training log saved to ./saved_models/resnet/regularization_params\\resnet_0.001_0.2.json\n",
            "is cuda False\n",
            "Batch count 0\n",
            "Epoch 1/1, Loss: 1.8285, Accuracy: 0.4844, F1-score: 0.3942\n",
            "Model saved to ./saved_models/resnet/regularization_params\\ResNetPretrained_1.pth\n",
            "Training log saved to ./saved_models/resnet/regularization_params\\resnet_0.001_0.5.json\n",
            "is cuda False\n",
            "Batch count 0\n",
            "Epoch 1/1, Loss: 1.6865, Accuracy: 0.4141, F1-score: 0.3614\n",
            "Model saved to ./saved_models/resnet/regularization_params\\ResNetPretrained_1.pth\n",
            "Training log saved to ./saved_models/resnet/regularization_params\\resnet_0.001_0.7.json\n",
            "is cuda False\n",
            "Batch count 0\n",
            "Epoch 1/1, Loss: 1.3900, Accuracy: 0.4766, F1-score: 0.4415\n",
            "Model saved to ./saved_models/resnet/regularization_params\\ResNetPretrained_1.pth\n",
            "Training log saved to ./saved_models/resnet/regularization_params\\resnet_0.0001_0.2.json\n",
            "is cuda False\n",
            "Batch count 0\n",
            "Epoch 1/1, Loss: 1.3300, Accuracy: 0.5156, F1-score: 0.5197\n",
            "Model saved to ./saved_models/resnet/regularization_params\\ResNetPretrained_1.pth\n",
            "Training log saved to ./saved_models/resnet/regularization_params\\resnet_0.0001_0.5.json\n",
            "is cuda False\n",
            "Batch count 0\n",
            "Epoch 1/1, Loss: 1.2966, Accuracy: 0.5859, F1-score: 0.5348\n",
            "Model saved to ./saved_models/resnet/regularization_params\\ResNetPretrained_1.pth\n",
            "Training log saved to ./saved_models/resnet/regularization_params\\resnet_0.0001_0.7.json\n"
          ]
        }
      ],
      "source": [
        "for weight_decay, dropout in regularization_param_combinations:\n",
        "    trainer = ModelTrainer(\n",
        "        model=resnet,\n",
        "        train_loader=train_loader,\n",
        "        device=device,\n",
        "        optimizer_type=\"adam\",\n",
        "        learning_rate=0.001,\n",
        "        weight_decay=weight_decay,\n",
        "        dropout=dropout,\n",
        "        log_file=f\"resnet_{weight_decay}_{dropout}.json\",\n",
        "        save_dir=\"./saved_models/resnet/regularization_params\",\n",
        "        max_batches=max_batches,\n",
        "    )\n",
        "    trainer.train(n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpWgo1pyOhrD"
      },
      "source": [
        "### Best model to be tested on dataset altered through data augmentation techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4BNAMVAOhrE"
      },
      "outputs": [],
      "source": [
        "train_rotated = load_data(\n",
        "    \"./data/train\",\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    transform=random_rotation_transform(),\n",
        "    num_workers=2,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
